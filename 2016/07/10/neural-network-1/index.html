<!DOCTYPE html>
<html lang="en">

  <head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-79896728-2', 'auto');
  ga('send', 'pageview');

</script>

  <title>构建一个神经网络：成本函数 和 梯度下降 &middot; Puxuan</title>

  <!-- CSS -->
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto+Slab:700|PT+Serif:400,400italic,700,700italic" type="text/css">
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/hyde.css">
  <!-- <link rel="stylesheet" href="/public/css/jekyll-github.css"> -->
  <link rel="stylesheet" href="/public/css/styles/atelier-forest-light.css">
  <script src="/public/css/highlight.pack.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>

  <!-- Insert to your webpage before the </head> -->
  <script src="/public/audioplayerengine/jquery.js"></script>
  <script src="/public/audioplayerengine/amazingaudioplayer.js"></script>
  <link rel="stylesheet" type="text/css" href="/public/audioplayerengine/initaudioplayer-1.css">
  <script src="/public/audioplayerengine/initaudioplayer-1.js"></script>
  <!-- End of head section HTML codes -->

  <link rel="canonical" href="http://puxuan.coding.me//2016/07/10/neural-network-1/" />

  

  

  

  <style>
    .content a,
    .related-posts li a:hover {
      color: #949667;
    }
    ::selection {
      color: #fff;
      background: #949667;
    }
    ::-moz-selection {
      color: #fff;
      background: #949667;
    }
  </style>

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/apple-touch-icon-144-precomposed.png">
  <link rel="shortcut icon" href="/public/favicon.ico">

  <!-- RSS -->
  <link rel="alternate" type="application/atom+xml" title="Puxuan" href="http://puxuan.coding.me//atom.xml">

</head>


  <body>
    <a id="_menu" class="menu" href="#_sidebar">☰</a>

    <main class="content container">
      


<article class="post">
  <h1 class="post-title">构建一个神经网络：成本函数 和 梯度下降</h1>
  <div class="post-date">
    <time datetime="2016-07-10T00:00:00+08:00">07/10/16</time>
    <span>on <a href="/tag/code/">Technique</a></span>
  </div>
  
  <hr/>
  <h2 id="section">如何构建一个神经网络</h2>
<p>一般的神经网络中，我们都有多层、非线性的激活函数（activation function），而且每个节点都有偏置项。</p>

<p>在这里，我们暂时先只写一层，一个权重参数 w，输出没有激活函数，没有偏置项。</p>

<h3 id="section-1">先导入依赖</h3>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="c">#设置 random 的 seed，使随机变成伪随机</span>
<span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre>
</div>

<h3 id="section-2">定义目标函数</h3>

<p>在这个例子中，目标函数  <span class="MathJax_Preview">\mathbf{t}=f(\mathbf{x})+\mathcal{N}(0,0.2)</span><script type="math/tex">\mathbf{t}=f(\mathbf{x})+\mathcal{N}(0,0.2)</script></p>

<p>其中 <span class="MathJax_Preview">\mathcal{N}(0,0.2)</span><script type="math/tex">\mathcal{N}(0,0.2)</script>是我们加进去的高斯噪声（正态分布）,  <span class="MathJax_Preview">f(\mathbf{x})=\mathbf{x}*2</span><script type="math/tex">f(\mathbf{x})=\mathbf{x}*2</script> .</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="c"># 产生一个一致(0,1)分布的20个数据, x.shape = (20,)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">20</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span><span class="o">*</span><span class="mi">2</span>

<span class="n">noise_variance</span> <span class="o">=</span> <span class="mf">0.2</span>

<span class="c"># x.shape[0] = 20, randn 输出一个20(*1)的标准正态分布矩阵</span>
<span class="n">noise</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">*</span> <span class="n">noise_variance</span>

<span class="n">t</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">noise</span>
</code></pre>
</div>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="s">'o'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'t'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="n">f</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">f</span><span class="p">(</span><span class="mi">1</span><span class="p">)],</span> <span class="s">'b-'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'f(x)'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'$x$'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'$t$'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">'inputs (x) vs targets (t)'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre>
</div>

<p><img src="/public/img/nn1/output_5_0.png" alt="png" /></p>

<h3 id="section-3">定义成本函数</h3>

<p>我们现在的模型是 <span class="MathJax_Preview">\mathbf{y} = \mathbf{x}*w</span><script type="math/tex">\mathbf{y} = \mathbf{x}*w</script>。</p>

<p>我们优化的目的是使 <span class="MathJax_Preview">\xi = \sum_{i=1}^{N} \Vert t_i - y_i \Vert ^2</span><script type="math/tex">\xi = \sum_{i=1}^{N} \Vert t_i - y_i \Vert ^2</script> 取到最小值。</p>

<p>神经网络是通过 <strong>nn(x,w)</strong> 函数来实现的；成本函数是通过 <strong>cost(y,t)</strong> 来实现的。</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="k">def</span> <span class="nf">nn</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">w</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">*</span> <span class="n">w</span>

<span class="k">def</span> <span class="nf">cost</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">t</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">((</span><span class="n">t</span><span class="o">-</span><span class="n">y</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="nb">sum</span><span class="p">()</span>
</code></pre>
</div>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">ws</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>  <span class="c"># ws 是一个 list, 包含0-4之间的100个均匀分布的数</span>
<span class="n">cost_ws</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">vectorize</span><span class="p">(</span><span class="k">lambda</span> <span class="n">w</span><span class="p">:</span> <span class="n">cost</span><span class="p">(</span><span class="n">nn</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span> <span class="p">,</span> <span class="n">t</span><span class="p">))(</span><span class="n">ws</span><span class="p">)</span>  <span class="c"># ws 中每个值对应的 cost</span>

<span class="c"># 制图</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ws</span><span class="p">,</span> <span class="n">cost_ws</span><span class="p">,</span> <span class="s">'r-'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'$w$'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'$</span><span class="se">\\</span><span class="s">xi$'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">'cost vs. weight'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre>
</div>

<p><img src="/public/img/nn1/output_8_0.png" alt="png" /></p>

<p>从图中我们可以看出来，w=2 的时候 <span class="MathJax_Preview">\xi</span><script type="math/tex">\xi</script> 值最低。w=2 也是我们为 f(x) 选定的斜率。</p>

<p>注意这个方程是一个凸函数，所以只有一个最小值。</p>

<h2 id="section-4">优化成本函数</h2>

<p>这个例子中最佳权重 w 用肉眼都可以看出来。但是大多数情况下问题没有这么简单，比如</p>

<ul>
  <li>当遇到 Rastrigin function 的时候:</li>
</ul>

<div class="MathJax_Preview">f(\mathbf{x}) = An + \sum_{i=1}^n[x_i^2 - A cos(2\pi x_i)]</div>
<script type="math/tex; mode=display">f(\mathbf{x}) = An + \sum_{i=1}^n[x_i^2 - A cos(2\pi x_i)]</script>

<p>其中 <span class="MathJax_Preview">A=10</span><script type="math/tex">A=10</script> 且 <span class="MathJax_Preview">x_i \in [-5.12, +5.12]</span><script type="math/tex">x_i \in [-5.12, +5.12]</script>. 在 <span class="MathJax_Preview">x=0</span><script type="math/tex">x=0</script> 取最小值 <span class="MathJax_Preview">f(x) = 0</span><script type="math/tex">f(x) = 0</script> .</p>

<ul>
  <li>当遇到多维的情况时：每一个参数都会增加一维。</li>
</ul>

<p>所以我们需要优化这个算法。</p>

<h3 id="section-5">梯度下降</h3>

<p>最常用的优化算法之一就是梯度下降算法。它的原理是在成本函数的某一点（参数）上对 <span class="MathJax_Preview">\xi</span><script type="math/tex">\xi</script> 求导数，然后在负梯度方向更新参数。参数 w 被迭代更新，步数与负梯度成比例：</p>

<div class="MathJax_Preview">w(k+1) = w(k) - \Delta w(k)</div>
<script type="math/tex; mode=display">w(k+1) = w(k) - \Delta w(k)</script>

<p>其中 w(k) 是第 k 次迭代中 w 的值。</p>

<p><span class="MathJax_Preview">\Delta w</span><script type="math/tex">\Delta w</script> 的定义为：
<span class="MathJax_Preview">\Delta w = \mu \frac{\partial \xi}{\partial w}</span><script type="math/tex">\Delta w = \mu \frac{\partial \xi}{\partial w}</script></p>

<p>其中，<span class="MathJax_Preview">\mu</span><script type="math/tex">\mu</script> 是“学习速度”(learning rate)，也就是在梯度方向上移动的距离。</p>

<p>对于样本<span class="MathJax_Preview">i</span><script type="math/tex">i</script>, 梯度可以根据链式法则进行拆分:</p>

<div class="MathJax_Preview">\frac{\partial \xi_i}{\partial w} = \frac{\partial y_i}{\partial w} \frac{\partial \xi_i}{\partial y_i}</div>
<script type="math/tex; mode=display">\frac{\partial \xi_i}{\partial w} = \frac{\partial y_i}{\partial w} \frac{\partial \xi_i}{\partial y_i}</script>

<p>其中 <span class="MathJax_Preview">\xi_i</span><script type="math/tex">\xi_i</script> 是平方差成本，所以 <span class="MathJax_Preview">{\partial \xi_i}/{\partial y_i}</span><script type="math/tex">{\partial \xi_i}/{\partial y_i}</script> 可以写成：</p>

<div class="MathJax_Preview">\frac{\partial \xi_i}{\partial y_i} = \frac{\partial (t_i - y_i)^2}{\partial y_i} = - 2 (t_i - y_i) = 2 (y_i - t_i)</div>
<script type="math/tex; mode=display">\frac{\partial \xi_i}{\partial y_i} = \frac{\partial (t_i - y_i)^2}{\partial y_i} = - 2 (t_i - y_i) = 2 (y_i - t_i)</script>

<p>又因为 <span class="MathJax_Preview">y_i = x_i * w</span><script type="math/tex">y_i = x_i * w</script>，所以我们可以把 <span class="MathJax_Preview">{\partial y_i}/{\partial w}</span><script type="math/tex">{\partial y_i}/{\partial w}</script> 写成：</p>

<div class="MathJax_Preview">\frac{\partial y_i}{\partial w} = \frac{\partial (x_i * w)}{\partial w} = x_i</div>
<script type="math/tex; mode=display">\frac{\partial y_i}{\partial w} = \frac{\partial (x_i * w)}{\partial w} = x_i</script>

<p>所以样本<span class="MathJax_Preview">i</span><script type="math/tex">i</script>的 <span class="MathJax_Preview">\Delta w</span><script type="math/tex">\Delta w</script> 最终写成：</p>

<div class="MathJax_Preview">\Delta w = \mu * \frac{\partial \xi_i}{\partial w} = \mu * 2 x_i (y_i - t_i)</div>
<script type="math/tex; mode=display">\Delta w = \mu * \frac{\partial \xi_i}{\partial w} = \mu * 2 x_i (y_i - t_i)</script>

<p>梯度下降属于<strong>在线处理(online processing)</strong>，与之对应的是<strong>批量处理(batch processing)</strong>。在批量处理中，我们只是简单地把所有样本的梯度相加：</p>

<div class="MathJax_Preview">\Delta w = \mu * 2 * \sum_{i=1}^{N} x_i (y_i - t_i)</div>
<script type="math/tex; mode=display">\Delta w = \mu * 2 * \sum_{i=1}^{N} x_i (y_i - t_i)</script>

<h3 id="section-6">使用梯度下降</h3>

<p>随机选取一个初始的参数值 w, 然后使用 <span class="MathJax_Preview">\Delta w</span><script type="math/tex">\Delta w</script> 不断地对 w 进行更新直到收敛。</p>

<p>学习速度 <span class="MathJax_Preview">\mu</span><script type="math/tex">\mu</script> 应该拿出来作为一个超参(hyperparameter)，每个神经网络都有不同的学习速度。</p>

<p>梯度 <span class="MathJax_Preview">{\partial \xi}/{\partial w}</span><script type="math/tex">{\partial \xi}/{\partial w}</script> 由函数 <strong>gradient(w, x, t)</strong> 来实现。<span class="MathJax_Preview">\Delta w</span><script type="math/tex">\Delta w</script> 是由 <strong>delta_w(w_k, x, t, learning_rate)</strong> 来计算。</p>

<p>循环执行四次，且打印出当前的 <span class="MathJax_Preview">w</span><script type="math/tex">w</script> 和 <span class="MathJax_Preview">\xi</span><script type="math/tex">\xi</script>。</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="k">def</span> <span class="nf">gradient</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
    <span class="k">return</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">x</span> <span class="o">*</span> <span class="p">(</span><span class="n">nn</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span> <span class="o">-</span> <span class="n">t</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">delta_w</span><span class="p">(</span><span class="n">w_k</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">gradient</span><span class="p">(</span><span class="n">w_k</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span><span class="o">.</span><span class="nb">sum</span><span class="p">()</span>

<span class="c"># 设置初始 w 值</span>
<span class="n">w</span> <span class="o">=</span> <span class="mf">0.1</span>

<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.1</span>


<span class="n">nb_of_iterations</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">w_cost</span> <span class="o">=</span> <span class="p">[(</span><span class="n">w</span><span class="p">,</span> <span class="n">cost</span><span class="p">(</span><span class="n">nn</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">w</span><span class="p">),</span> <span class="n">t</span><span class="p">))]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nb_of_iterations</span><span class="p">):</span>
    <span class="n">dw</span> <span class="o">=</span> <span class="n">delta_w</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">)</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">w</span> <span class="o">-</span> <span class="n">dw</span>
    <span class="n">w_cost</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">w</span><span class="p">,</span> <span class="n">cost</span><span class="p">(</span><span class="n">nn</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">w</span><span class="p">),</span> <span class="n">t</span><span class="p">)))</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">w_cost</span><span class="p">)):</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'w({}): {:.4f} </span><span class="se">\t</span><span class="s"> cost: {:.4f}'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">w_cost</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">w_cost</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">]))</span>
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>w(0): 0.1000 	 cost: 13.6197
w(1): 1.5277 	 cost: 1.1239
w(2): 1.8505 	 cost: 0.4853
w(3): 1.9234 	 cost: 0.4527
w(4): 1.9399 	 cost: 0.4510
</code></pre>
</div>

<p>可以观察到，第二次迭代就很接近我们的目标了。</p>

<p>我们试着画个图看看，把前两次梯度下降显示出来。</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ws</span><span class="p">,</span> <span class="n">cost_ws</span><span class="p">,</span> <span class="s">'r-'</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">w_cost</span><span class="p">)</span><span class="o">-</span><span class="mi">2</span><span class="p">):</span>
    <span class="n">w1</span><span class="p">,</span> <span class="n">c1</span> <span class="o">=</span> <span class="n">w_cost</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="n">w2</span><span class="p">,</span> <span class="n">c2</span> <span class="o">=</span> <span class="n">w_cost</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">w1</span><span class="p">,</span> <span class="n">c1</span><span class="p">,</span> <span class="s">'bo'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">w1</span><span class="p">,</span> <span class="n">w2</span><span class="p">],[</span><span class="n">c1</span><span class="p">,</span> <span class="n">c2</span><span class="p">],</span> <span class="s">'b-'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">w1</span><span class="p">,</span> <span class="n">c1</span><span class="o">+</span><span class="mf">0.5</span><span class="p">,</span> <span class="s">'$w({})$'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'$w$'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'$</span><span class="se">\\</span><span class="s">xi$'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Gradient descent updates plotted on cost function'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre>
</div>

<p><img src="/public/img/nn1/output_15_0.png" alt="png" /></p>

<p>我们用十次梯度下降的迭代，与原来的方法相比，画图比较一下。</p>

<p>（两条线都过(0,0)一点，因为我们没有加偏置项(bias term)）</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">w</span> <span class="o">=</span> <span class="mi">0</span>

<span class="n">nb_of_iterations</span> <span class="o">=</span> <span class="mi">10</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nb_of_iterations</span><span class="p">):</span>
    <span class="n">dw</span> <span class="o">=</span> <span class="n">delta_w</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">)</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">w</span> <span class="o">-</span> <span class="n">dw</span>
</code></pre>
</div>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="s">'o'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'t'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="n">f</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">f</span><span class="p">(</span><span class="mi">1</span><span class="p">)],</span> <span class="s">'b-'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'f(x)'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="o">*</span><span class="n">w</span><span class="p">,</span> <span class="mi">1</span><span class="o">*</span><span class="n">w</span><span class="p">],</span> <span class="s">'r-'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'fitted line'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'input x'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'target t'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">'input vs. target'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre>
</div>

<p><img src="/public/img/nn1/output_18_0.png" alt="png" /></p>


</article>


<aside class="author">
  <h2 class="aside-title">About</h2>

  
  <img class="me" src="/public/img/profile.jpg" alt="Puxuan Yu"/>
  

  <p>Software Engineering @ WuhanU 🇨🇳 , ISTJ.</p>

</aside>


<aside class="related">
  <h2 class="aside-title">Related Posts</h2>
  <ul class="related-posts">
    
    
    
      
      
        <li>
          <h4>
            <a href="/2016/12/07/image-segmention/">
              <span>Efficient Graph-based Image Segmentation</span>
              <small>12/07/16</small>
            </a>
          </h4>
        </li>
      
    
      
      
        <li>
          <h4>
            <a href="/2016/11/11/intro-to-xgboost/">
              <span>XGBoost详解</span>
              <small>11/11/16</small>
            </a>
          </h4>
        </li>
      
    
      
      
        <li>
          <h4>
            <a href="/2016/10/28/nnfml1/">
              <span>机器学习中的神经网络-笔记(1)</span>
              <small>10/28/16</small>
            </a>
          </h4>
        </li>
      
    
      
      
    
  </ul>
</aside>


<!-- 多说评论框 start -->
	<div class="ds-thread" data-thread-key='/2016/07/10/neural-network-1' data-title="构建一个神经网络：成本函数 和 梯度下降" data-url='http://puxuan.coding.me//2016/07/10/neural-network-1/'></div>
<!-- 多说评论框 end -->
<!-- 多说公共JS代码 start (一个网页只需插入一次) -->
<script type="text/javascript">
var duoshuoQuery = {short_name:"lucius0814"};
	(function() {
		var ds = document.createElement('script');
		ds.type = 'text/javascript';ds.async = true;
		ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
		ds.charset = 'UTF-8';
		(document.getElementsByTagName('head')[0] 
		 || document.getElementsByTagName('body')[0]).appendChild(ds);
	})();
	</script>
<!-- 多说公共JS代码 end -->


    </main>

    





<div   id="_backdrop" class="backdrop"></div>
<aside id="_sidebar" class="sidebar" style="background-image:url('/public/img/code.jpg')">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1><a href="/">Puxuan</a></h1>
      <p>10^14 synapses in a brain, and 10^9 seconds in a life.</p>

    </div>

    <nav class="sidebar-nav">
      <ul>
        
          
          <li>
            <a class="sidebar-nav-item " href="/tag/code/">Technique</a>
          </li>
        
          
          <li>
            <a class="sidebar-nav-item " href="/tag/travel/">Travel</a>
          </li>
        
          
          <li>
            <a class="sidebar-nav-item " href="/tag/music/">Music</a>
          </li>
        
          
          <li>
            <a class="sidebar-nav-item " href="/tag/other/">Misc</a>
          </li>
        

        

        
        
          
            
          
        
          
            
            <li>
              <a class="sidebar-nav-item " href="/about/">About</a>
            </li>
            
          
        
          
        
          
        
          
            
          
        
          
        
          
        
          
        
      </ul>
    </nav>

    <div class="sidebar-social">
      
        <a href="https://github.com/PxYu" target="_blank"><span class="icon-github"></span></a>

      

      
        <a href="https://instagram.com/pxyuwhu" target="_blank"><span class="icon-instagram"></span></a>

      

      
        <a href="https://twitter.com/pxyuwhu" target="_blank"><span class="icon-twitter-square"></span></a>

      

      
        <a href="https://facebook.com/martin.yu.5249" target="_blank"><span class="icon-facebook-square"></span></a>

      

      
        <a href="https://weibo.com/u/3290896193" target="_blank"><span class="icon-weibo"></span></a>

      


    </div>
  </div>
</aside>


    <script src="/public/js/hydejack.js" async></script>
  </body>
</html>
